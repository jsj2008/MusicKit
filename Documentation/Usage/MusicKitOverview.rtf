{\rtf0\ansi{\fonttbl\f0\fnil Times-Roman;\f3\ftech Symbol;\f1\fmodern Courier;}
\paperw12240
\paperh14020
\margl2160
\margr1060
\pard\tx780\tx1920\tx3060\tx4200\tx5340\tx6480\tx7620\f0\b0\i0\ulnone\qc\fs28\fc0\cf0 	OVERVIEW OF THE NeXT MUSIC KIT\
\
\
		David  A. Jaffe\

\f3 ã
\f0 NeXT, Inc. 1989\
\

\ql The NeXT Music Kit is an object-oriented library implemented in Objective-C for the design of music applications for the NeXT computer.  The Music Kit provides the "model" function in a model/view/controller paradigm.  Graphic manipulation and display are left to the application.  The Music Kit addresses three issues: the representation of music (with an emphasis on synthesis), the performance of music, and the synthesis /processing of music on the built-in DSP. In addressing these areas, a basic design goal of the Music Kit is to combine the performance and interactive aspects of MIDI protocol with the generality and expressive richness of the MUSIC 5 language  (and similar systems).  That is, the Music Kit combines the gestural control of MIDI with the timbral control of MUSIC 5, while extending the flexibility of both. \
\
This paper assumes a familiarity with the basics of object-oriented programming and MIDI. We use the following conventions:  All classes begin with a capital letter.  Instance methods begin with "
\b -
\b0 " as in "
\b -perform
\b0 ".  Classes and instances are used interchangeably when the context is clear.  For example, "Performers send Notes to Instruments" implies "instances of the Performer class send instances of the Note class to instances of the Instrument class."\
\
The Music Kit classes fall into three categories: representation classes, performance classes, and synthesis/processing classes.  Each group can be used independently of the other two.  Inheritance is used sparingly and only in cases where it promotes conceptual clarity. \
\
\

\i Representation
\i0 \
\
\
Music is represented in a three-level hierarchy.  A 
\b Score
\b0  represents a section of musical material and contains 
\b Parts
\b0 .  A Part is analogous to an instrumental part in an orchestral score and corresponds to a rendering in a particular manner. It contains a sorted list of 
\b Notes
\b0 , each representing an event with a particular onset time. \
\
A Note contains a list of attribute-value pairs called 
\b parameters
\b0 , used to specify attributes such as frequency, amplitude, and timbre.  The value of a parameter has a type that may be integer number, floating-point number, character string, Envelope object, WaveTable object, or application-defined object.  The precise meaning of a parameter, like that of an Objective-C message , depends on the object that uses it. For example, the parameter 
\b bright
\b0  might be interpreted by a plucked string simulation as "pluck harder" and by an oboe simulation as "blow harder".  Applications may define their own parameters. For example, a graphic display application might have a parameter indicating how a Note is to be drawn on the screen. \
\
A Note's character is identified by its  
\b noteType
\b0 .  The noteTypes are  
\b noteDur
\b0  (a musical note with a duration, as in MUSIC 5), 
\b noteOn
\b0  (the onset of a musical note), 
\b noteOff
\b0  (the onset of the completion of a musical note), 
\b noteUpdate
\b0  (a change in a sounding musical note) and 
\b mute
\b0  (none of the above).   Another important piece of information associated with a note is its 
\b noteTag
\b0 .  NoteTags are used to associate noteOns and noteOffs or indicate how a Note fits into a 
\b phrase
\b0 . NoteTags are further explained below:\
\
In a performance context, the future is not known -- each musical note appears as a noteOn event followed by a noteOff event.  There needs to be some way to know which noteOff corresponds to a particular noteOn.  MIDI uses key number and channel (poly mode) or just channel (mono mode), but this is problematic for three reasons. First of all, the total number of tags is limited to 128 X 16 (poly mode) or 16 (mono mode), making it difficult to mix MIDI streams with overlapping channels.  Secondly, MIDI must change its matching strategy from poly mode to mono mode to implement phrase-level structure.  Finally, frequency matching is impractical in a general computer music system that allows frequency to be expressed as a floating-point number or Envelope.\
\
The Music Kit solves the problem by decoupling matching from frequency.  Music Kit noteTags are integers that match noteOns with noteOffs. This allows phrase-level structure to be expressed without a special mono mode.  Notes with the same noteTag are considered to be part of the same phrase.  The number of possible simultaneous phrases is virtually unlimited. There is no need to store the frequency in the noteOff, since the noteTag conveys all matching information.  Finally, it is not necessary to ensure that each noteOn be matched by a noteOff -- a series of noteOns with the same noteTag is concluded by a single noteOff with that noteTag. \
\
The noteTag is optional for noteUpdates and noteDurs. A noteUpdate with no noteTag applies to all voices managed by a particular Instrument (see below). For example, MIDI pitch bend is implemented this way. A noteDur needs a noteTag only if it's part of a phrase or has associated with it some noteUpdates. Mutes never have noteTags.\
\
A Score can be stored in a 
\b scorefile
\b0 .  Scorefiles are in ASCII format and can be easily created and modified with a text editor.  In addition, the Music Kit provides a language called 
\b ScoreFile
\b0  that allows simple programming constructs such as variables, assignments and arithmetic expressions to be added to a scorefile.  A Score can also read and write 
\b Standard MIDI Files.
\b0  To remain compatible with MIDI, automatic translation between MIDI and Music Kit semantics is provided. To support collision-free mixing, noteTags are remapped when a file is read into a Music Kit applicaton. \
\
\

\i Performance
\i0 \
\
\
A Music Kit 
\b performance
\b0  can be configured to do a wide variety of tasks such as MIDI or DSP sequencing, animation, MIDI real-time processing (such as MIDI echo, channel mapping, or doubling), and filtering of Note streams. Performance is  based on a discrete simulation data flow model, where the data are Note objects flowing via messages from 
\b Performers
\b0  to 
\b Instruments
\b0  in time order.  The entire performance is under the control of a 
\b Conductor
\b0 , that acts as a non-preemptive scheduler, dispatching messages at the appropriate time. Multiple Conductors with different tempi are supported. \
\
It is the Performer's job to dispatch Note objects to its outputs. It is the Instrument's job to "realize" Notes sent to its inputs.  For example, a 
\b PartPerformer
\b0  performs Notes from a Part, and a 
\b SynthInstrument
\b0  realizes the Notes it receives by playing them on the DSP.  Connections are made dynamically between the outputs of Performers and the inputs of Instruments. Each output or input can have multiple connections.  The performance proceeds by the Conductor's sending the 
\b -perform
\b0  message to the Performer next scheduled to receive that message. The Performer then dispatches its Note(s) to its outputs, invoking each Instrument's 
\b -realizeNote:
\b0  method.\
\
An application can subclass Performer and Instrument to generate or realize Notes in some application-specific manner. For example, a display Instrument class could realize Notes by putting them on the screen, while an algorithmic Performer could generate and dispatch Notes based on some mathematical algorithm. \
\
A 
\b NoteFilter
\b0  is a special kind of Instrument that contains outputs as well as inputs. A NoteFilter receives Notes, performs some subclass-specific operation on them, then forwards them to its outputs. It can also supress Notes , use them as triggers, or create and start a new Performer in response to Notes it receives. NoteFilters allow Note processing modules to be packaged cleanly and applied dynamically as needed. \
\

\i \
DSP Synthesis and Processing
\i0 \
\
\
The Music Kit provides a mechanism for doing synthesis in real time at a level of generality analogous to that of MUSIC5 and far surpassing that of traditional synthesizers.  While most synthesizers are based on a single synthesis strategy such as FM, the Music Kit can implement a wide variety of strategies. In addition, by bringing the synthesis engine together with the control stream in a single computer, the Music Kit makes possible an unprecedented level of expressive control over the sound itself. \
\
Music Kit synthesis is controlled by the 
\b Orchestra
\b0 .  The Orchestra is instantiable, so the Music Kit can handle multiple DSP chips, should a multi-DSP board become available. The Orchestra handles allocation of the three types of synthesis modules, 
\b UnitGenerators
\b0 ,
\b  SynthData, 
\b0 and
\b  SynthPatches
\b0 . \
\
UnitGenerators
\b  
\b0 and SynthData are the basic building blocks of DSP synthesis.  Each UnitGenerator subclass implements a particular synthesis function.  The Music Kit provides a library of UnitGenerator subclasses for doing such common synthesis operations as oscillators, envelope handlers, filters, mixers , etc. In addition, you can create your own unit generator in 56001 assembly language, with the help of an extensive set of macros provided by the Music Kit and use the tool 
\b dspwrap
\b0  to automatically generates the corresponding UnitGenerator subclass. SynthData instances are used for wave tables, delay memory, constants, and for  
\b patchpoints 
\b0 that interconnect  UnitGenerators.  For example, simple frequency modulation can be implemented by setting the output of an oscillator to write to a patchpoint that is read by the frequency input of another oscillator.\
\
UnitGenerators and SynthData may be combined into SynthPatches. Each SynthPatch subclass implements a particular synthesis strategy. It does this by defining a configuration of synthesis resources and a set of methods to translate Notes into UnitGenerator messages. These methods are invoked in response to 
\b -noteOn:, -noteUpdate:
\b0 , and
\b  -noteOff:
\b0  messages, where the argument is the Note of the appropriate type. There is also a method that is invoked in response to the completion of the release portion of the musical note.\
\
In a Music Kit performance, SynthPatches are managed by SynthInstruments. Each SynthInstrument manages SynthPatches of a particular SynthPatch subclass and each SynthPatch instance implements a single voice. The SynthInstrument receives Notes and dispatches them to the appropriate SynthPatch, based on the noteTags.  If no SynthPatch is available to play a Note, the SynthInstrument preempts its oldest running SynthPatch (a different preemption strategy can be substituted).  Support is provided for legato connection between Notes on the same noteTag.  If a SynthPatch receives a noteOn for a noteTag that is already sounding, a smooth transition to the new Note is made.\
\
\

\i Summary
\i0 \
\
\
The Music Kit suggests a variety of exciting applications. Its vitality will be determined by the imagination of the software developers who build on its foundation.  We feel that the power of the concepts on which it is based, such as the abstraction of performance, the extensibility of the Note, and the modular approach to synthesis, is capable of meeting the needs of a wide variety of application developers.\
\
\

\i Acknowledgements
\i0 \
\
\
Julius Smith is the author of the DSP unit generator macro system, many of the unit generators themselves, the DSP system, and the DSP library functions.  Doug Fulton and Mike Mcnabb made large contributions. Other people at NeXT who have contributed to the design of the Music Kit include  Lee Boynton, Roger Dannenberg, Doug Keislar, Gregg Kellogg, Dana Massie, Andy Moorer, and John Strawn. The design was also influenced by the work of Bill Schottstaedt, David Anderson, and others in the computer music community.\
\
\

\pard\tx1080\tx1440\tx1800\li720\fc0\cf0 This paper is copyright  
\f3\fs22 ã
\f0\fs28  NeXT Inc., 1989.\
\

}
