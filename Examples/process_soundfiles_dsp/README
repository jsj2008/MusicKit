	NON-REAL-TIME SOUNDFILE PROCESSING THROUGH THE DSP USING THE MUSIC KIT

		By David Jaffe and Julius Smith, CCRMA, Stanford University


This is an example of how to process soundfiles through the DSP using the Music Kit. It illustrates non-real-time soundfile processing.  For real-time processing of sound, use the DSP SSI port.   See the Orchestra documentation for details.

This example must be used with Music Kit release 3.1 or later.  Since support for writing a soundfile is not currently (as of Sept, 1994) available for Intel hardware, this example works only with NeXT hardware.

The Makefile on this directory generates two programs: "extractchannel" and "process_soundfiles_dsp". (The underbars are because 'processsoundsdsp' is too hard to read!)

"extractchannel" is a utility that extracts one channel of a stereo soundfile. The following example extracts a channel of the file Rooster.snd and puts it in the file rooster.snd

	extractchannel /NextLibrary/Sounds/Rooster.snd rooster.snd

"process_soundfiles_dsp" reads a scorefile from standard input and writes a soundfile to the name specified on the command line. Example:

	process_soundfiles_dsp -o /tmp/dspmixed.snd < test.score 

(Note that test.score requires rooster.snd.)

process_soundfiles_dsp is actually just a version of playscorefile that writes a soundfile rather than playing in real time.  It has three SynthPatches loaded into it.  The three SynthPatches are EnvelopeSound, ResonSound, and Pluck.  EnvelopeSound takes a mono soundfile, applies an amplitude envelope to it, and positions it in the stereo field.  ResonSound is somewhat more exotic--it passes its sound through an all-pole resonator.  Pluck is included just to illustrate that synthesis patches can be included as well.  Any number of patches may be included up to the limit imposed by the DSP memory size.

The scorefile lists mono 16 bit files that are to be mixed and enveloped.  Note that no sampling rate conversion is done. The sampling rate of the file must match the sampling rate in the scorefile "info" statement. Also note that a duration (or noteOff) must be supplied.  The duration may be shorter than the soundfile, in which case the file is truncated. An example scorefile and soundfile, test.score and FrogMono.snd, are provided. test.score combines several versions of FrogMono.snd with different envelopes and resonators and mixes in a few synthesized notes from Pluck.
	
The source files in the process_soundfiles_dsp program are as follows:

* readsound.asm
	an example of a dsp unitgenerator macro that reads from a DSP memory 
	buffer. This is used by ReadsoundUG.m.

* ReadsoundUG.m: 
	an example of a UnitGenerator class that reads a mono 16-bit 
	soundfile and writes it to a patchpoint, thus allowing the soundfile
	to be processed.

* EnvelopeSound.m
	an example of how this UnitGenerator is used in a SynthPatch to 
	apply an envelope to a sound.  See "scorefile parameters" below.

* ResonSound.m
	an example of how this UnitGenerator is used in a SynthPatch to 
	apply a resonator to a sound.  See "scorefile parameters" below.

* writeScorefileToSoundfile.m
	an example of how to write DSP-generated sound to a soundfile.
	This is really just a slightly modified version of 
	/LocalDeveloper/Examples/MusicKit/playscorefile/playscorefile.m.	

Scorefile parameters:

	EnvelopeSound responds to the following parameters:
	
		ampEnv - amplitude envelope
		ampAtt - amplitude envelope attack time
		ampRel - amplitude envelope release time
		amp - amplitude of sound
		bearing - between -45 and 45

	ResonSound responds to all of the parameters of EnvelopeSound, plus:

		freq - frequency of resonator
		feebackGain - A number between 0 and 1.0.  High values may
				cause clipping

WHERE TO GO FROM HERE?

There are many sound processing algorithms that can be implemented as SynthPatches.  If you make an interesting one, please post it to the Net or send it to us.

WHAT WOULD IT TAKE TO MAKE IT PLAY IN REAL TIME?

The sound is loaded to the DSP through the timed message queue, sample by sample, rather than via DMA.  This technique is not fast enough for real time.  DMA is more efficient, but more difficult to program due to its asynchronous nature.  In particular, it is hard to do DMA purely in a unit generator; DMA support for soundfile processing has to be in the DSP system itself.  Some preliminary support for soundfile processing is in the current DSP monitor, but significant work is required to make it work and this project is currently low on our priority list.  If you have an interest in making it work, we would be delighted if you would do so and send us the implementation so we can integrate it into the Music Kit release.



